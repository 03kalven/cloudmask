{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tqdm import tqdm\n",
    "from random import Random\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(32)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=static_weighted_binary_crossentropy,\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.MeanIoU(num_classes=2)],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to preprocessed training data created from trainingData.ipynb\n",
    "X_PATH = 'E:/SUBDIVS/img'\n",
    "Y_PATH = 'E:/SUBDIVS/mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to calculate weight_zero for the staticWeightedBinaryCrossEntropy function\n",
    "# value = fraction of one pixels / total pixels in training dataset\n",
    "\n",
    "all_y = os.listdir(Y_PATH)\n",
    "\n",
    "# shuffling data before train/validation split\n",
    "Random(333).shuffle(all_y)\n",
    "\n",
    "SPLIT_train_val = int(len(all_y) * 0.7)\n",
    "rolling_sum = 0\n",
    "for num, img in tqdm(enumerate(all_y[:SPLIT_train_val])):\n",
    "    tempY = np.load(os.path.join(Y_PATH, img))\n",
    "    rolling_sum += tempY.sum()\n",
    "\n",
    "print(rolling_sum / (SPLIT_train_val * 484 * 484))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains the model\n",
    "\n",
    "BATCH_SIZE = 6\n",
    "\n",
    "all_x, all_y = os.listdir(X_PATH), os.listdir(Y_PATH)\n",
    "all_x.sort()\n",
    "all_y.sort()\n",
    "\n",
    "# seeded shuffling data before train/validation split\n",
    "Random(333).shuffle(all_x)\n",
    "Random(333).shuffle(all_y)\n",
    "\n",
    "# 70% training, 15% validation, 15% testing\n",
    "SPLIT_train_val = int(len(all_x) * 0.7)\n",
    "SPLIT_val_test = int(len(all_x) * 0.85)\n",
    "\n",
    "# iterable function that returns (img, mask) tuples from the training data. Performs augmentation on the data (normal, horizontal flip, vertical flip, horizontal & vertical flip)\n",
    "def iter_train():\n",
    "    for num in range(0, SPLIT_train_val * 4):\n",
    "        index = int(num / 4)\n",
    "        rem = num % 4\n",
    "        img = np.load(os.path.join(X_PATH, all_x[index])).astype(np.uint8)\n",
    "        mask = np.load(os.path.join(Y_PATH, all_y[index])).astype(bool)\n",
    "        if rem == 0:\n",
    "            pass\n",
    "        elif rem == 1:\n",
    "            img = np.flip(img, axis=0)\n",
    "            mask = np.flip(mask, axis=0)\n",
    "        elif rem == 2:\n",
    "            img = np.flip(img, axis=1)\n",
    "            mask = np.flip(mask, axis=1)\n",
    "        else:\n",
    "            img = np.flip(np.flip(img, axis=0), axis=1)\n",
    "            mask = np.flip(np.flip(mask, axis=0), axis=1)\n",
    "        yield img, mask\n",
    "\n",
    "\n",
    "# iterable function that returns (img, mask) tuples from the validation data\n",
    "def iter_validate():\n",
    "    for num in range(SPLIT_train_val, SPLIT_val_test):\n",
    "        img = np.load(os.path.join(X_PATH, all_x[num])).astype(np.uint8)\n",
    "        mask = np.load(os.path.join(Y_PATH, all_y[num])).astype(bool)\n",
    "        yield img, mask\n",
    "\n",
    "\n",
    "gen_train = iter_train()\n",
    "gen_validate = iter_validate()\n",
    "\n",
    "data_train = (\n",
    "    tf.data.Dataset.from_generator(\n",
    "        iter_train,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(668, 668, 3), dtype=tf.uint8),\n",
    "            tf.TensorSpec(shape=(484, 484, 1), dtype=tf.bool),\n",
    "        ),\n",
    "    )\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "data_validate = (\n",
    "    tf.data.Dataset.from_generator(\n",
    "        iter_validate,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(668, 668, 3), dtype=tf.uint8),\n",
    "            tf.TensorSpec(shape=(484, 484, 1), dtype=tf.bool),\n",
    "        ),\n",
    "    )\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# optional\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, monitor=\"val_loss\"),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=\"cloud_model\", histogram_freq=1, write_images=True, update_freq=200\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"checkpoints/cloud_model_weights.ckpt\", verbose=1, save_best_only=True\n",
    "    ),\n",
    "]\n",
    "\n",
    "results = model.fit(\n",
    "    data_train, validation_data=data_validate, verbose=1, epochs=250, callbacks=callbacks\n",
    ")\n",
    "\n",
    "# for tensorboard run command in activated python environment: python -m tensorboard.main --logdir=\"path\\to\\CloudMask Final\\cloud_model\" --host=127.0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the model\n",
    "model.load_weights(\"checkpoints/cloud_model_weights.ckpt/\")\n",
    "model.save(\"save_cloud_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests the model\n",
    "\n",
    "all_x = os.listdir(X_PATH)\n",
    "all_y = os.listdir(Y_PATH)\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    \"save_cloud_model\",\n",
    "    custom_objects={\"static_weighted_binary_crossentropy\": static_weighted_binary_crossentropy},\n",
    ")\n",
    "\n",
    "# shuffling data before train/validation split\n",
    "Random(333).shuffle(all_x)\n",
    "Random(333).shuffle(all_y)\n",
    "\n",
    "SPLIT_train_val = int(len(all_x) * 0.7)\n",
    "SPLIT_val_test = int(len(all_x) * 0.85)\n",
    "\n",
    "\n",
    "def iterTest():\n",
    "    for num in range(SPLIT_val_test, int(len(all_x))):\n",
    "        img = np.load(os.path.join(X_PATH, all_x[num])).astype(np.uint8)\n",
    "        mask = np.load(os.path.join(Y_PATH, all_y[num])).astype(bool)\n",
    "        yield img, mask\n",
    "\n",
    "\n",
    "gen_test = iterTest()\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "data_test = (\n",
    "    tf.data.Dataset.from_generator(\n",
    "        iterTest,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(668, 668, 3), dtype=tf.uint8),\n",
    "            tf.TensorSpec(shape=(484, 484, 1), dtype=tf.bool),\n",
    "        ),\n",
    "    )\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "results = model.evaluate(data_test, verbose=1)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd046897d2504d950700c98dc1f45b2d3c2958afac842e556b70974641745c3e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
