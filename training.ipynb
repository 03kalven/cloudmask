{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tqdm import tqdm\n",
    "from random import Random\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 668, 668, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 668, 668, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 666, 666, 32) 896         lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 666, 666, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 664, 664, 32) 9248        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 664, 664, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 332, 332, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 330, 330, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 330, 330, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 328, 328, 64) 36928       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 328, 328, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 164, 164, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 162, 162, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 162, 162, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 160, 160, 128 147584      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 160, 160, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 80, 80, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 78, 78, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 78, 78, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 76, 76, 256)  590080      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 76, 76, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 38, 38, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 36, 36, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 36, 36, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 34, 34, 512)  2359808     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 34, 34, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "center_crop (CenterCrop)        (None, 68, 68, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 68, 68, 256)  524544      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 68, 68, 512)  0           center_crop[0][0]                \n",
      "                                                                 conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 66, 66, 256)  1179904     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 66, 66, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 256)  590080      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_crop_1 (CenterCrop)      (None, 128, 128, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 128 131200      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 256 0           center_crop_1[0][0]              \n",
      "                                                                 conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 126, 126, 128 295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 126, 126, 128 512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 124, 124, 128 147584      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 124, 124, 128 512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_crop_2 (CenterCrop)      (None, 248, 248, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 248, 248, 64) 32832       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 248, 248, 128 0           center_crop_2[0][0]              \n",
      "                                                                 conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 246, 246, 64) 73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 246, 246, 64) 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 244, 244, 64) 36928       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 244, 244, 64) 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_crop_3 (CenterCrop)      (None, 488, 488, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 488, 488, 32) 8224        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 488, 488, 64) 0           center_crop_3[0][0]              \n",
      "                                                                 conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 486, 486, 32) 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 486, 486, 32) 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 484, 484, 32) 9248        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 484, 484, 32) 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 484, 484, 1)  33          batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 7,771,873\n",
      "Trainable params: 7,765,985\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = getModel(32)\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), loss = staticWeightedBincrossentropy, metrics = ['accuracy', tf.keras.metrics.MeanIoU(num_classes = 2)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to preprocessed training data created from trainingData.ipynb\n",
    "X_PATH = 'E:/SUBDIVS/img'\n",
    "Y_PATH = 'E:/SUBDIVS/mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30998it [02:26, 211.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03692684935147368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# used to calculate weight_zero for the staticWeightedBinaryCrossEntropy function\n",
    "# value = fraction of one pixels / total pixels in training dataset\n",
    "\n",
    "allY = os.listdir(Y_PATH)\n",
    "\n",
    "# shuffling data before train/validation split\n",
    "Random(333).shuffle(allY)\n",
    "\n",
    "SPLIT_TrainVal = int(len(allY)*0.7)\n",
    "rollingSum = 0\n",
    "for num, img in tqdm(enumerate(allY[:SPLIT_TrainVal])):\n",
    "    tempY = np.load(os.path.join(Y_PATH,img))\n",
    "    rollingSum += tempY.sum()\n",
    "\n",
    "print(rollingSum / (SPLIT_TrainVal*484*484))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains the model\n",
    "\n",
    "BATCH_SIZE = 6\n",
    "\n",
    "allX = os.listdir(X_PATH)\n",
    "allY = os.listdir(Y_PATH)\n",
    "allX.sort()\n",
    "allY.sort()\n",
    "\n",
    "# seeded shuffling data before train/validation split\n",
    "Random(333).shuffle(allX)\n",
    "Random(333).shuffle(allY)\n",
    "\n",
    "# 70% training, 15% validation, 15% testing\n",
    "SPLIT_TrainVal = int(len(allX)*0.7)\n",
    "SPLIT_ValTest = int(len(allX)*0.85)\n",
    "\n",
    "# iterable function that returns (img, mask) tuples from the training data. Performs augmentation on the data (normal, horizontal flip, vertical flip, horizontal & vertical flip)\n",
    "def iterTrain():\n",
    "    for num in range(0, SPLIT_TrainVal*4):\n",
    "        index = int(num / 4)\n",
    "        rem = num % 4\n",
    "        img = np.load(os.path.join(X_PATH,allX[index])).astype(np.uint8)\n",
    "        mask = np.load(os.path.join(Y_PATH,allY[index])).astype(bool)\n",
    "        if rem == 0:\n",
    "            pass\n",
    "        elif rem == 1:\n",
    "            img = np.flip(img, axis=0)\n",
    "            mask = np.flip(mask, axis=0)\n",
    "        elif rem == 2:\n",
    "            img = np.flip(img, axis=1)\n",
    "            mask = np.flip(mask, axis=1)\n",
    "        else:\n",
    "            img = np.flip(np.flip(img, axis=0), axis=1)\n",
    "            mask = np.flip(np.flip(mask, axis=0), axis=1)\n",
    "        yield img, mask\n",
    "\n",
    "# iterable function that returns (img, mask) tuples from the validation data\n",
    "def iterValidate():\n",
    "    for num in range(SPLIT_TrainVal, SPLIT_ValTest):\n",
    "        img = np.load(os.path.join(X_PATH,allX[num])).astype(np.uint8)\n",
    "        mask = np.load(os.path.join(Y_PATH,allY[num])).astype(bool)\n",
    "        yield img, mask\n",
    "\n",
    "genTrain = iterTrain()\n",
    "genValidate = iterValidate()\n",
    "\n",
    "dataTrain = tf.data.Dataset.from_generator(iterTrain, output_signature=(\n",
    "    tf.TensorSpec(shape=(668, 668, 3), dtype=tf.uint8),\n",
    "    tf.TensorSpec(shape=(484, 484, 1), dtype=tf.bool)\n",
    ")).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "dataValidate = tf.data.Dataset.from_generator(iterValidate, output_signature=(\n",
    "    tf.TensorSpec(shape=(668, 668, 3), dtype=tf.uint8),\n",
    "    tf.TensorSpec(shape=(484, 484, 1), dtype=tf.bool)\n",
    ")).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# optional\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='cloudModel', histogram_freq=1, write_images=True, update_freq=200),\n",
    "        tf.keras.callbacks.ModelCheckpoint('checkpoints/cloudModel_weights.ckpt', verbose=1, save_best_only=True)\n",
    "        ]\n",
    "\n",
    "results = model.fit(dataTrain, validation_data=dataValidate, verbose=1, epochs=250, callbacks=callbacks)\n",
    "\n",
    "# for tensorboard run command in activated python environment: python -m tensorboard.main --logdir=\"path\\to\\CloudMask Final\\model_name\" --host=127.0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: save_sUNET32V2\\assets\n"
     ]
    }
   ],
   "source": [
    "# saves the model\n",
    "model.load_weights('checkpoints/cloudModel_weights.ckpt/')\n",
    "model.save('save_cloudModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6643/6643 [==============================] - 154s 22ms/step - loss: 0.0087 - accuracy: 0.9667 - mean_io_u: 0.4812\n",
      "[0.008651204407215118, 0.9667173027992249, 0.48119229078292847]\n"
     ]
    }
   ],
   "source": [
    "# tests the model\n",
    "\n",
    "allX = os.listdir(X_PATH)\n",
    "allY = os.listdir(Y_PATH)\n",
    "\n",
    "model = tf.keras.models.load_model('save_cloudModel', custom_objects={'staticWeightedBincrossentropy': staticWeightedBincrossentropy})\n",
    "\n",
    "# shuffling data before train/validation split\n",
    "Random(333).shuffle(allX)\n",
    "Random(333).shuffle(allY)\n",
    "\n",
    "SPLIT_TrainVal = int(len(allX)*0.7)\n",
    "SPLIT_ValTest = int(len(allX)*0.85)\n",
    "\n",
    "def iterTest():\n",
    "    for num in range(SPLIT_ValTest, int(len(allX))):\n",
    "        img = np.load(os.path.join(X_PATH,allX[num])).astype(np.uint8)\n",
    "        mask = np.load(os.path.join(Y_PATH,allY[num])).astype(bool)\n",
    "        yield img, mask\n",
    "\n",
    "genTest = iterTest()\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "dataTest = tf.data.Dataset.from_generator(iterTest, output_signature=(\n",
    "    tf.TensorSpec(shape=(668, 668, 3), dtype=tf.uint8),\n",
    "    tf.TensorSpec(shape=(484, 484, 1), dtype=tf.bool)\n",
    ")).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "results = model.evaluate(dataTest, verbose=1)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd046897d2504d950700c98dc1f45b2d3c2958afac842e556b70974641745c3e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
