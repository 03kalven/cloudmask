{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tqdm import tqdm\n",
    "from random import Random\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(8, 4)\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), loss = weighted_binary_crossentropy, metrics = [tf.keras.metrics.BinaryAccuracy(threshold=0.912), tf.keras.metrics.BinaryIoU(threshold=0.912)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to preprocessed training data created from preprocessing_training_data.ipynb\n",
    "PATH = 'data/train_processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to calculate weight_zero for the static_weighted_binary_crossentropy function\n",
    "# value = fraction of one pixels / total pixels in training dataset\n",
    "\n",
    "all_data = os.listdir(PATH)\n",
    "\n",
    "# shuffling data before train/validation split\n",
    "Random(333).shuffle(all_data)\n",
    "\n",
    "SPLIT_train_val = int(len(all_data) * 0.7)\n",
    "rolling_sum = 0\n",
    "for num, img in tqdm(enumerate(all_data[:SPLIT_train_val])):\n",
    "    temp = np.load(os.path.join(PATH, img))['mask'].astype(np.uint8)\n",
    "    rolling_sum += temp.sum()\n",
    "\n",
    "print(rolling_sum / (SPLIT_train_val * 484**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains the model\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "all_data = os.listdir(PATH)\n",
    "all_data.sort()\n",
    "\n",
    "# seeded shuffling data before train/validation split\n",
    "Random(333).shuffle(all_data)\n",
    "\n",
    "# 70% training, 15% validation, 15% testing\n",
    "SPLIT_train_val = int(len(all_data) * 0.7)\n",
    "SPLIT_val_test = int(len(all_data) * 0.85)\n",
    "\n",
    "# iterable function that returns (img, mask) tuples from the training data. Performs augmentation on the data (normal, horizontal flip, vertical flip, horizontal & vertical flip)\n",
    "def iter_train():\n",
    "    for num in range(0, SPLIT_train_val * 4):\n",
    "        index = int(num / 4)\n",
    "        rem = num % 4\n",
    "        npz = np.load(os.path.join(PATH, all_data[index]))\n",
    "        img = npz['mdgm'].astype(np.uint8)\n",
    "        mask = npz['mask'].astype(bool)\n",
    "        if rem == 0:\n",
    "            pass\n",
    "        elif rem == 1:\n",
    "            img = np.flip(img, axis=0)\n",
    "            mask = np.flip(mask, axis=0)\n",
    "        elif rem == 2:\n",
    "            img = np.flip(img, axis=1)\n",
    "            mask = np.flip(mask, axis=1)\n",
    "        else:\n",
    "            img = np.flip(np.flip(img, axis=0), axis=1)\n",
    "            mask = np.flip(np.flip(mask, axis=0), axis=1)\n",
    "        yield img, mask\n",
    "\n",
    "def iter_validate():\n",
    "    for num in range(SPLIT_train_val, SPLIT_val_test):\n",
    "        npz = np.load(os.path.join(PATH, all_data[num]))\n",
    "        img = npz['mdgm'].astype(np.uint8)\n",
    "        mask = npz['mask'].astype(bool)\n",
    "        yield img, mask\n",
    "\n",
    "data_train = tf.data.Dataset.from_generator(iter_train, output_signature=(\n",
    "    tf.TensorSpec(shape=(668, 668, 3), dtype=tf.uint8),\n",
    "    tf.TensorSpec(shape=(484, 484, 1), dtype=tf.bool)\n",
    ")).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "data_validate = tf.data.Dataset.from_generator(iter_validate, output_signature=(\n",
    "    tf.TensorSpec(shape=(668, 668, 3), dtype=tf.uint8),\n",
    "    tf.TensorSpec(shape=(484, 484, 1), dtype=tf.bool)\n",
    ")).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# optional\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, monitor=\"val_loss\"),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=\"cloud_model\", histogram_freq=1, write_images=True, update_freq=200\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"checkpoints/cloud_model_weights.ckpt\", verbose=1, save_best_only=True\n",
    "    ),\n",
    "]\n",
    "\n",
    "results = model.fit(\n",
    "    data_train, validation_data=data_validate, verbose=1, epochs=250, callbacks=callbacks\n",
    ")\n",
    "\n",
    "# for tensorboard run command in activated python environment: python -m tensorboard.main --logdir=\"path\\to\\cloudmask\\cloud_model\" --host=127.0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the model\n",
    "model.load_weights(\"checkpoints/cloud_model_weights.ckpt/\")\n",
    "model.save(\"save_cloud_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests the model\n",
    "\n",
    "all_data = os.listdir(PATH)\n",
    "all_data.sort()\n",
    "\n",
    "# seeded shuffling data before train/validation split\n",
    "Random(333).shuffle(all_data)\n",
    "\n",
    "# 70% training, 15% validation, 15% testing\n",
    "SPLIT_val_test = int(len(all_data) * 0.85)\n",
    "\n",
    "model = tf.keras.models.load_model('save_cloud_model', custom_objects={'weighted_binary_crossentropy': weighted_binary_crossentropy})\n",
    "\n",
    "def iter_test():\n",
    "    for num in range(SPLIT_val_test, len(all_data)):\n",
    "        npz = np.load(os.path.join(PATH, all_data[num]))\n",
    "        img = npz['mdgm'].astype(np.uint8)\n",
    "        mask = npz['mask'].astype(bool)\n",
    "        yield img, mask\n",
    "\n",
    "BATCH_SIZE=1\n",
    "data_test = tf.data.Dataset.from_generator(iter_test, output_signature=(\n",
    "    tf.TensorSpec(shape=(668, 668, 3), dtype=tf.uint8),\n",
    "    tf.TensorSpec(shape=(484, 484, 1), dtype=tf.bool)\n",
    ")).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "res = model.evaluate(data_test)\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c8a685ad8b7eea5e0816a67a07b8526bfcbbfc8274c619382b138e85f29b471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
